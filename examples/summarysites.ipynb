{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Access public bleaching data from MERMAID API\n",
    "\n",
    "Run binder (ctrl + click to open in new tab): [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/data-mermaid/jupyter.git/main?urlpath=git-pull%3Frepo%3Dhttps%253A%252F%252Fgithub.com%252Fdata-mermaid%252Fmermaid-api%26urlpath%3Dlab%252Ftree%252Fmermaid-api%252Fexamples%252Fsummarysites.ipynb%26branch%3Dmaster)\n",
    "\n",
    "This is a basic demonstration of accessing the unauthenticated site-level aggregated data endpoint from the MERMAID API.\n",
    "\n",
    "- \"unauthenticated\": Data retrieved from this endpoint depends on the per-protocol data sharing policies selected the the project's administrators. If a protocol's data policy is set to `private` then the number of sample units at the site will be returned, but not the actual (average) data. Use authenticated endpoints for access to data in projects to which a user belongs.\n",
    "- \"site-level\": % cover is collected per quadrat, then averaged for the sample unit (quadrat collection): `percent_hard_avg` etc. The site summary endpoint averages these averages (e.g. `percent_hard_avg_avg`) for all sample units collected at the site. A site in MERMAID is unique to a project, i.e. there can be multiple `site`s at the same location, across projects. It is also possible for the averaged data to span multiple dates (within a project). For date-specific averages, the authenticated `sampleevent` endpoint should be used.\n",
    "\n",
    "For documentation of most other API endpoints, see https://mermaid-api.readthedocs.io/en/latest/. Also useful is the [Insomnia](https://insomnia.rest/) collection included with the [API repository](https://mermaid-api.readthedocs.io/mermaid_api.insomnia_collection.json)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Set up\n",
    "\n",
    "Import required libraries and set constants (change `api.datamermaid.org` to `dev-api.datamermaid.org` if desired).\n",
    "\n",
    "Set filters as key/value pairs, if needed. Without them all sites in MERMAID are returned. A full list of filters is available [here](https://mermaid-api.readthedocs.io/en/latest/aggregated.html#site-summary-view)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from pprint import pprint\n",
    "\n",
    "API_URL = \"https://api.datamermaid.org/v1\"\n",
    "SUMMARY_SITES = \"summarysites/\"\n",
    "\n",
    "filters = {\n",
    "    # \"project_name\": \"Kenya MACMON 2016-17\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "session.headers.update({\"content-type\": \"application/json\",})\n",
    "url = f\"{API_URL}/{SUMMARY_SITES}\"\n",
    "\n",
    "request = requests.Request(\"GET\", url=url, params=filters)\n",
    "prepped = session.prepare_request(request)\n",
    "print(f\"url: {prepped.url}\")\n",
    "response = session.send(prepped).json()\n",
    "print(f\"Got {response['count']} sites total\")\n",
    "\n",
    "sites = response[\"results\"]\n",
    "while response[\"next\"]:\n",
    "    request = requests.Request(\"GET\", url=response[\"next\"])\n",
    "    prepped = session.prepare_request(request)\n",
    "    print(f\"next page url: {prepped.url}\")\n",
    "    response = session.send(prepped).json()\n",
    "    sites.extend(response[\"results\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Filter data for sites containing bleaching data\n",
    "\n",
    "The bleaching quadrat collection protocol contains two sets of observations, one that counts the number of colonies for specific taxa and their condition (`colonies_bleached`), and one that estimates percent cover per quadrat (`quadrat_benthic_percent`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sites_with_bleaching_data = [\n",
    "    site for site in sites\n",
    "    if \"colonies_bleached\" in site[\"protocols\"]\n",
    "       and \"quadrat_benthic_percent\" in site[\"protocols\"]\n",
    "]\n",
    "print(f\"Sites with bleaching data: {len(sites_with_bleaching_data)}\")\n",
    "\n",
    "# uncomment to examine first two results in full\n",
    "# pprint(sites_with_bleaching_data[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create analysis-ready dataframe\n",
    "\n",
    "This step just demmonstrates one common analysis pattern. Other site properties could be included if needed, or other non-dataframe-based ways of using the `site` objects could be employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "indicators = []\n",
    "\n",
    "for site in sites_with_bleaching_data:\n",
    "    bleaching_benthic = site[\"protocols\"][\"quadrat_benthic_percent\"]\n",
    "    bleaching_colonies = site[\"protocols\"][\"colonies_bleached\"]\n",
    "    benthic = {}\n",
    "    if \"benthicpit\" in site[\"protocols\"]:\n",
    "        benthic = site[\"protocols\"][\"benthicpit\"].get(\"percent_cover_benthic_category_avg\", {})\n",
    "    if \"benthiclit\" in site[\"protocols\"]:\n",
    "        benthic = site[\"protocols\"][\"benthiclit\"].get(\"percent_cover_benthic_category_avg\", {})\n",
    "\n",
    "    site_data = {\n",
    "        \"hard_coral_benthic\": benthic.get(\"Hard coral\"),\n",
    "        \"soft_coral_benthic\": benthic.get(\"Soft coral\"),\n",
    "        \"macroalgae_benthic\": benthic.get(\"Macroalgae\"),\n",
    "        \"hard_coral_bleaching\": bleaching_benthic.get(\"percent_hard_avg_avg\"),\n",
    "        \"soft_coral_bleaching\": bleaching_benthic.get(\"percent_soft_avg_avg\"),\n",
    "        \"macroalgae_bleaching\": bleaching_benthic.get(\"percent_algae_avg_avg\"),\n",
    "        \"percent_normal_avg\": bleaching_colonies.get(\"percent_normal_avg\"),\n",
    "        \"percent_pale_avg\": bleaching_colonies.get(\"percent_pale_avg\"),\n",
    "        \"percent_bleached_avg\": bleaching_colonies.get(\"percent_bleached_avg\"),\n",
    "    }\n",
    "\n",
    "    indicators.append(site_data)\n",
    "\n",
    "df = pd.DataFrame(indicators)\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
