{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Access public bleaching data from MERMAID API\n",
    "\n",
    "Run in binder: [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/data-mermaid/jupyter.git/main?urlpath=git-pull%3Frepo%3Dhttps%253A%252F%252Fgithub.com%252Fdata-mermaid%252Fmermaid-api%26urlpath%3Dlab%252Ftree%252Fmermaid-api%252Fexamples%252Fsummarysites.ipynb%26branch%3Dmaster)\n",
    "\n",
    "This is a basic demonstration of accessing the unauthenticated site-level aggregated data endpoint from the MERMAID API.\n",
    "\n",
    "- \"unauthenticated\": Data retrieved from this endpoint depends on the per-protocol data sharing policies selected the the project's administrators. If a protocol's data policy is set to `private` then the number of sample units at the site will be returned, but not the actual (average) data. Use authenticated endpoints for access to data in projects to which a user belongs.\n",
    "- \"site-level\": % cover is collected per quadrat, then averaged for the sample unit (quadrat collection): `percent_hard_avg` etc. The site summary endpoint averages these averages (e.g. `percent_hard_avg_avg`) for all sample units collected at the site. A site in MERMAID is unique to a project, i.e. there can be multiple `site`s at the same location, across projects. It is also possible for the averaged data to span multiple dates (within a project). For date-specific averages, the authenticated `sampleevent` endpoint should be used.\n",
    "\n",
    "For documentation of most other API endpoints, see https://mermaid-api.readthedocs.io/en/latest/. Also useful is the [Insomnia](https://insomnia.rest/) collection included with the [API repository](https://mermaid-api.readthedocs.io/mermaid_api.insomnia_collection.json)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set up\n",
    "\n",
    "Import required libraries and set constants (change `api.datamermaid.org` to `dev-api.datamermaid.org` if desired).\n",
    "\n",
    "Set filters as key/value pairs, if needed. Without them all sites in MERMAID are returned. A full list of filters is available [here](https://mermaid-api.readthedocs.io/en/latest/aggregated.html#site-summary-view)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from pprint import pprint\n",
    "\n",
    "API_URL = \"https://api.datamermaid.org/v1\"\n",
    "SUMMARY_SITES = \"summarysites/\"\n",
    "\n",
    "filters = {\n",
    "    # \"project_name\": \"Kenya MACMON 2016-17\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fetch data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url: https://api.datamermaid.org/v1/summarysites/\n",
      "Got 2906 sites total\n",
      "next page url: http://api.datamermaid.org/v1/summarysites/?page=2\n",
      "next page url: http://api.datamermaid.org/v1/summarysites/?page=3\n",
      "next page url: http://api.datamermaid.org/v1/summarysites/?page=4\n",
      "next page url: http://api.datamermaid.org/v1/summarysites/?page=5\n",
      "next page url: http://api.datamermaid.org/v1/summarysites/?page=6\n",
      "next page url: http://api.datamermaid.org/v1/summarysites/?page=7\n",
      "next page url: http://api.datamermaid.org/v1/summarysites/?page=8\n",
      "next page url: http://api.datamermaid.org/v1/summarysites/?page=9\n",
      "next page url: http://api.datamermaid.org/v1/summarysites/?page=10\n",
      "next page url: http://api.datamermaid.org/v1/summarysites/?page=11\n",
      "next page url: http://api.datamermaid.org/v1/summarysites/?page=12\n",
      "next page url: http://api.datamermaid.org/v1/summarysites/?page=13\n",
      "next page url: http://api.datamermaid.org/v1/summarysites/?page=14\n",
      "next page url: http://api.datamermaid.org/v1/summarysites/?page=15\n",
      "next page url: http://api.datamermaid.org/v1/summarysites/?page=16\n",
      "next page url: http://api.datamermaid.org/v1/summarysites/?page=17\n",
      "next page url: http://api.datamermaid.org/v1/summarysites/?page=18\n",
      "next page url: http://api.datamermaid.org/v1/summarysites/?page=19\n",
      "next page url: http://api.datamermaid.org/v1/summarysites/?page=20\n",
      "next page url: http://api.datamermaid.org/v1/summarysites/?page=21\n",
      "next page url: http://api.datamermaid.org/v1/summarysites/?page=22\n",
      "next page url: http://api.datamermaid.org/v1/summarysites/?page=23\n",
      "next page url: http://api.datamermaid.org/v1/summarysites/?page=24\n",
      "next page url: http://api.datamermaid.org/v1/summarysites/?page=25\n",
      "next page url: http://api.datamermaid.org/v1/summarysites/?page=26\n",
      "next page url: http://api.datamermaid.org/v1/summarysites/?page=27\n",
      "next page url: http://api.datamermaid.org/v1/summarysites/?page=28\n",
      "next page url: http://api.datamermaid.org/v1/summarysites/?page=29\n",
      "next page url: http://api.datamermaid.org/v1/summarysites/?page=30\n"
     ]
    }
   ],
   "source": [
    "session = requests.Session()\n",
    "session.headers.update({\"content-type\": \"application/json\",})\n",
    "url = f\"{API_URL}/{SUMMARY_SITES}\"\n",
    "\n",
    "request = requests.Request(\"GET\", url=url, params=filters)\n",
    "prepped = session.prepare_request(request)\n",
    "print(f\"url: {prepped.url}\")\n",
    "response = session.send(prepped).json()\n",
    "print(f\"Got {response['count']} sites total\")\n",
    "\n",
    "sites = response[\"results\"]\n",
    "while response[\"next\"]:\n",
    "    request = requests.Request(\"GET\", url=response[\"next\"])\n",
    "    prepped = session.prepare_request(request)\n",
    "    print(f\"next page url: {prepped.url}\")\n",
    "    response = session.send(prepped).json()\n",
    "    sites.extend(response[\"results\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Filter data for sites containing bleaching data\n",
    "\n",
    "The bleaching quadrat collection protocol contains two sets of observations, one that counts the number of colonies for specific taxa and their condition (`colonies_bleached`), and one that estimates percent cover per quadrat (`quadrat_benthic_percent`)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sites with bleaching data: 245\n"
     ]
    }
   ],
   "source": [
    "sites_with_bleaching_data = [\n",
    "    site for site in sites\n",
    "    if \"colonies_bleached\" in site[\"protocols\"]\n",
    "       and \"quadrat_benthic_percent\" in site[\"protocols\"]\n",
    "]\n",
    "print(f\"Sites with bleaching data: {len(sites_with_bleaching_data)}\")\n",
    "\n",
    "# uncomment to examine first two results in full\n",
    "# pprint(sites_with_bleaching_data[:2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create analysis-ready dataframe\n",
    "\n",
    "This step just demmonstrates one common analysis pattern. Other site properties could be included if needed, or other non-dataframe-based ways of using the `site` objects could be employed."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     hard_coral_benthic  soft_coral_benthic  macroalgae_benthic  \\\n",
      "0                   NaN                 NaN                 NaN   \n",
      "1                   NaN                 NaN                 NaN   \n",
      "2                   NaN                 NaN                 NaN   \n",
      "3                   NaN                 NaN                 NaN   \n",
      "4                   NaN                 NaN                 NaN   \n",
      "..                  ...                 ...                 ...   \n",
      "240                 NaN                 NaN                 NaN   \n",
      "241                 NaN                 NaN                 NaN   \n",
      "242                 NaN                 NaN                 NaN   \n",
      "243                 NaN                 NaN                 NaN   \n",
      "244                 NaN                 NaN                 NaN   \n",
      "\n",
      "     hard_coral_bleaching  soft_coral_bleaching  macroalgae_bleaching  \\\n",
      "0                    50.3                  28.1                   0.8   \n",
      "1                    49.2                   4.7                  10.6   \n",
      "2                    49.0                   0.0                   1.4   \n",
      "3                    39.3                   5.0                   2.3   \n",
      "4                    21.9                  14.0                   5.0   \n",
      "..                    ...                   ...                   ...   \n",
      "240                   NaN                   NaN                   NaN   \n",
      "241                   NaN                   NaN                   NaN   \n",
      "242                   NaN                   NaN                   NaN   \n",
      "243                   NaN                   NaN                   NaN   \n",
      "244                   NaN                   NaN                   NaN   \n",
      "\n",
      "     percent_normal_avg  percent_pale_avg  percent_bleached_avg  \n",
      "0                  91.8               1.7                   6.5  \n",
      "1                  90.1               8.3                   1.6  \n",
      "2                  92.9               4.4                   2.8  \n",
      "3                  84.5              13.8                   1.7  \n",
      "4                  82.2              15.1                   2.7  \n",
      "..                  ...               ...                   ...  \n",
      "240                 NaN               NaN                   NaN  \n",
      "241                 NaN               NaN                   NaN  \n",
      "242                 NaN               NaN                   NaN  \n",
      "243                 NaN               NaN                   NaN  \n",
      "244                 NaN               NaN                   NaN  \n",
      "\n",
      "[245 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "indicators = []\n",
    "\n",
    "for site in sites_with_bleaching_data:\n",
    "    bleaching_benthic = site[\"protocols\"][\"quadrat_benthic_percent\"]\n",
    "    bleaching_colonies = site[\"protocols\"][\"colonies_bleached\"]\n",
    "    benthic = {}\n",
    "    if \"benthicpit\" in site[\"protocols\"]:\n",
    "        benthic = site[\"protocols\"][\"benthicpit\"].get(\"percent_cover_by_benthic_category_avg\", {})\n",
    "    if \"benthiclit\" in site[\"protocols\"]:\n",
    "        benthic = site[\"protocols\"][\"benthiclit\"].get(\"percent_cover_by_benthic_category_avg\", {})\n",
    "\n",
    "    site_data = {\n",
    "        \"hard_coral_benthic\": benthic.get(\"Hard coral\"),\n",
    "        \"soft_coral_benthic\": benthic.get(\"Soft coral\"),\n",
    "        \"macroalgae_benthic\": benthic.get(\"Macroalgae\"),\n",
    "        \"hard_coral_bleaching\": bleaching_benthic.get(\"percent_hard_avg_avg\"),\n",
    "        \"soft_coral_bleaching\": bleaching_benthic.get(\"percent_soft_avg_avg\"),\n",
    "        \"macroalgae_bleaching\": bleaching_benthic.get(\"percent_algae_avg_avg\"),\n",
    "        \"percent_normal_avg\": bleaching_colonies.get(\"percent_normal_avg\"),\n",
    "        \"percent_pale_avg\": bleaching_colonies.get(\"percent_pale_avg\"),\n",
    "        \"percent_bleached_avg\": bleaching_colonies.get(\"percent_bleached_avg\"),\n",
    "    }\n",
    "\n",
    "    indicators.append(site_data)\n",
    "\n",
    "df = pd.DataFrame(indicators)\n",
    "print(df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}